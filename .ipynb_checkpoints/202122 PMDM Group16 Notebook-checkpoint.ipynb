{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8166466e",
   "metadata": {},
   "source": [
    "# The Spies Among US\n",
    "\n",
    "### Which citizens should be placed under close surveillance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892d1a9",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f4f85924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling as pp\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "'''from model_library import baseline\n",
    "from model_library import xgboost\n",
    "from model_library import svc\n",
    "from model_library import naive_bayes\n",
    "from model_library import knn\n",
    "from model_library import logistic_regression'''\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1910fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df_train = pd.read_csv('espionage_data.csv')\n",
    "df_test = pd.read_csv('espionage_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "509569ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       8000 non-null   int64  \n",
      " 1   ID_ORIGINAL              8000 non-null   int64  \n",
      " 2   Gender                   8000 non-null   object \n",
      " 3   Foreign_Citizenship      7862 non-null   object \n",
      " 4   Age                      8000 non-null   int64  \n",
      " 5   Frequent_Traveler        7923 non-null   object \n",
      " 6   Cellphone_Usage          8000 non-null   object \n",
      " 7   Household_Size           7670 non-null   float64\n",
      " 8   Spy                      8000 non-null   int64  \n",
      " 9   Satisfaction_Level       7670 non-null   float64\n",
      " 10  Occupation               7876 non-null   object \n",
      " 11  Political_Participation  7876 non-null   object \n",
      " 12  Social_Person            7924 non-null   object \n",
      " 13  Area_Residence           7924 non-null   object \n",
      " 14  Military_Service         7924 non-null   object \n",
      " 15  Household_Income         8000 non-null   int64  \n",
      "dtypes: float64(2), int64(5), object(9)\n",
      "memory usage: 1000.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b8a0d85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493 entries, 0 to 492\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ID                       493 non-null    int64  \n",
      " 1   ID_ORIGINAL              493 non-null    int64  \n",
      " 2   Gender                   493 non-null    object \n",
      " 3   Foreign_Citizenship      486 non-null    object \n",
      " 4   Age                      493 non-null    int64  \n",
      " 5   Frequent_Traveler        490 non-null    object \n",
      " 6   Cellphone_Usage          493 non-null    object \n",
      " 7   Household_Size           476 non-null    float64\n",
      " 8   Satisfaction_Level       476 non-null    float64\n",
      " 9   Occupation               489 non-null    object \n",
      " 10  Political_Participation  489 non-null    object \n",
      " 11  Social_Person            485 non-null    object \n",
      " 12  Area_Residence           485 non-null    object \n",
      " 13  Military_Service         485 non-null    object \n",
      " 14  Household_Income         457 non-null    float64\n",
      "dtypes: float64(3), int64(3), object(9)\n",
      "memory usage: 57.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0c92487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate profiling report\n",
    "#df_train['Spy'] = df_train['Spy'].astype('float64')\n",
    "#df_train['Spy'] = df_train['Spy'].astype('object')\n",
    "#prof_train = pp.ProfileReport(df_train)\n",
    "#prof_train.to_file(output_file='output_train.html')\n",
    "\n",
    "#prof_test = pp.ProfileReport(df_test)\n",
    "#prof_test.to_file(output_file='output_test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e0f5cf04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_ORIGINAL</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Foreign_Citizenship</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frequent_Traveler</th>\n",
       "      <th>Cellphone_Usage</th>\n",
       "      <th>Household_Size</th>\n",
       "      <th>Spy</th>\n",
       "      <th>Satisfaction_Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Political_Participation</th>\n",
       "      <th>Social_Person</th>\n",
       "      <th>Area_Residence</th>\n",
       "      <th>Military_Service</th>\n",
       "      <th>Household_Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>467329</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Government</td>\n",
       "      <td>No involvement</td>\n",
       "      <td>No</td>\n",
       "      <td>City</td>\n",
       "      <td>Never</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>461212</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>No involvement</td>\n",
       "      <td>No</td>\n",
       "      <td>City</td>\n",
       "      <td>Never</td>\n",
       "      <td>19610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>466216</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Private company</td>\n",
       "      <td>Strong involvement</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Country-side</td>\n",
       "      <td>Never</td>\n",
       "      <td>8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>462613</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Average</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Private company</td>\n",
       "      <td>No involvement</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Country-side</td>\n",
       "      <td>Never</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>465709</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>68</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Average</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Private company</td>\n",
       "      <td>Strong involvement</td>\n",
       "      <td>No</td>\n",
       "      <td>City</td>\n",
       "      <td>Never</td>\n",
       "      <td>8261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  ID_ORIGINAL  Gender Foreign_Citizenship  Age Frequent_Traveler  \\\n",
       "0  1000       467329  Female                  No   40               Yes   \n",
       "1  1001       461212  Female                  No   30                No   \n",
       "2  1002       466216    Male                  No   29                No   \n",
       "3  1003       462613  Female                 Yes   35                No   \n",
       "4  1004       465709    Male                 Yes   68               Yes   \n",
       "\n",
       "  Cellphone_Usage  Household_Size  Spy  Satisfaction_Level       Occupation  \\\n",
       "0             Low             1.0    1                 4.0       Government   \n",
       "1             Low             6.0    0                 1.0          Nothing   \n",
       "2             Low             4.0    0                 1.0  Private company   \n",
       "3         Average             5.0    0                 1.0  Private company   \n",
       "4         Average             2.0    1                 4.0  Private company   \n",
       "\n",
       "  Political_Participation Social_Person Area_Residence Military_Service  \\\n",
       "0          No involvement            No           City            Never   \n",
       "1          No involvement            No           City            Never   \n",
       "2      Strong involvement           Yes   Country-side            Never   \n",
       "3          No involvement           Yes   Country-side            Never   \n",
       "4      Strong involvement            No           City            Never   \n",
       "\n",
       "   Household_Income  \n",
       "0              7000  \n",
       "1             19610  \n",
       "2              8261  \n",
       "3              7000  \n",
       "4              8261  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ce79c0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID_ORIGINAL</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Foreign_Citizenship</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frequent_Traveler</th>\n",
       "      <th>Cellphone_Usage</th>\n",
       "      <th>Household_Size</th>\n",
       "      <th>Satisfaction_Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Political_Participation</th>\n",
       "      <th>Social_Person</th>\n",
       "      <th>Area_Residence</th>\n",
       "      <th>Military_Service</th>\n",
       "      <th>Household_Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000</td>\n",
       "      <td>460139</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>26</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Private company</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>City</td>\n",
       "      <td>Intervention in Libya</td>\n",
       "      <td>7566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9001</td>\n",
       "      <td>460648</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>No involvement</td>\n",
       "      <td>Yes</td>\n",
       "      <td>City</td>\n",
       "      <td>Intervention in Libya</td>\n",
       "      <td>10088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9002</td>\n",
       "      <td>460835</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>28</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Private company</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Yes</td>\n",
       "      <td>City</td>\n",
       "      <td>Intervention in Libya</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9003</td>\n",
       "      <td>461613</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Private company</td>\n",
       "      <td>Some involvement</td>\n",
       "      <td>Yes</td>\n",
       "      <td>City</td>\n",
       "      <td>Intervention in Libya</td>\n",
       "      <td>10088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9004</td>\n",
       "      <td>461721</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>26</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Low</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Private company</td>\n",
       "      <td>Strong involvement</td>\n",
       "      <td>Yes</td>\n",
       "      <td>City</td>\n",
       "      <td>Intervention in Libya</td>\n",
       "      <td>8827.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  ID_ORIGINAL  Gender Foreign_Citizenship  Age Frequent_Traveler  \\\n",
       "0  9000       460139    Male                  No   26                No   \n",
       "1  9001       460648  Female                 NaN   29                No   \n",
       "2  9002       460835  Female                 Yes   28               Yes   \n",
       "3  9003       461613  Female                  No   25               Yes   \n",
       "4  9004       461721    Male                  No   26               Yes   \n",
       "\n",
       "  Cellphone_Usage  Household_Size  Satisfaction_Level       Occupation  \\\n",
       "0             Low             6.0                 1.0  Private company   \n",
       "1             Low             1.0                 3.0          Nothing   \n",
       "2             Low             1.0                 3.0  Private company   \n",
       "3             Low             4.0                 1.0  Private company   \n",
       "4             Low             5.0                 1.0  Private company   \n",
       "\n",
       "  Political_Participation Social_Person Area_Residence       Military_Service  \\\n",
       "0                 Unknown           Yes           City  Intervention in Libya   \n",
       "1          No involvement           Yes           City  Intervention in Libya   \n",
       "2                 Unknown           Yes           City  Intervention in Libya   \n",
       "3        Some involvement           Yes           City  Intervention in Libya   \n",
       "4      Strong involvement           Yes           City  Intervention in Libya   \n",
       "\n",
       "   Household_Income  \n",
       "0            7566.0  \n",
       "1           10088.0  \n",
       "2               0.0  \n",
       "3           10088.0  \n",
       "4            8827.0  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986afa96",
   "metadata": {},
   "source": [
    "## Exploration & Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e12586c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ID, ID_ORIGINAL, Gender, Foreign_Citizenship, Age, Frequent_Traveler, Cellphone_Usage, Household_Size, Spy, Satisfaction_Level, Occupation, Political_Participation, Social_Person, Area_Residence, Military_Service, Household_Income]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [ID, ID_ORIGINAL, Gender, Foreign_Citizenship, Age, Frequent_Traveler, Cellphone_Usage, Household_Size, Satisfaction_Level, Occupation, Political_Participation, Social_Person, Area_Residence, Military_Service, Household_Income]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(df_train[df_train.duplicated()])\n",
    "print(df_test[df_test.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "841ed0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TRAIN ---\n",
      " Foreign_Citizenship        1.7250\n",
      "Frequent_Traveler          0.9625\n",
      "Household_Size             4.1250\n",
      "Satisfaction_Level         4.1250\n",
      "Occupation                 1.5500\n",
      "Political_Participation    1.5500\n",
      "Social_Person              0.9500\n",
      "Area_Residence             0.9500\n",
      "Military_Service           0.9500\n",
      "dtype: float64\n",
      "\n",
      "--- TEST ---\n",
      " Foreign_Citizenship        1.419878\n",
      "Frequent_Traveler          0.608519\n",
      "Household_Size             3.448276\n",
      "Satisfaction_Level         3.448276\n",
      "Occupation                 0.811359\n",
      "Political_Participation    0.811359\n",
      "Social_Person              1.622718\n",
      "Area_Residence             1.622718\n",
      "Military_Service           1.622718\n",
      "Household_Income           7.302231\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "train_null = df_train.isna().sum()/len(df_train)*100\n",
    "print('--- TRAIN ---\\n',train_null[train_null > 0])\n",
    "\n",
    "test_null = df_test.isna().sum()/len(df_test)*100\n",
    "print('\\n--- TEST ---\\n',test_null[test_null > 0])\n",
    "\n",
    "train_nulls = train_null[train_null > 0].index.tolist()\n",
    "test_nulls = test_null[test_null > 0].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c812e",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2f895c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "def encode_features(df,s):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[s])\n",
    "    df['CD_'+s] = le.transform(df[s])\n",
    "    return le\n",
    "\n",
    "# Pre-process data\n",
    "def prepare_data(df):\n",
    "    df_prep = df.copy()\n",
    "        \n",
    "    ## MISSING VALUES ##\n",
    "    # Fill missing values\n",
    "    df_prep['Area_Residence'] = df_prep['Area_Residence'].fillna('Unknown')\n",
    "    df_prep['Foreign_Citizenship'] = df_prep['Foreign_Citizenship'].fillna('Unknown')\n",
    "    df_prep['Frequent_Traveler'] = df_prep['Frequent_Traveler'].fillna('Unknown')    \n",
    "    df_prep['Occupation'] = df_prep['Occupation'].fillna('Unknown')\n",
    "    df_prep['Political_Participation'] = df_prep['Political_Participation'].fillna('Unknown')    \n",
    "    df_prep['Military_Service'] = df_prep['Military_Service'].fillna('Unknown')\n",
    "    df_prep['Social_Person'] = df_prep['Social_Person'].fillna('Unknown')\n",
    "    \n",
    "    # TO DO: Check if this is a good solution\n",
    "    df_prep['Household_Size'] = df_prep['Household_Size'].fillna('-1')    \n",
    "    df_prep['Satisfaction_Level'] = df_prep['Satisfaction_Level'].fillna('-1')\n",
    "    df_prep['Household_Income'] = df_prep['Household_Income'].fillna('-1')\n",
    "    \n",
    "    # Drop columns with missing values\n",
    "    #df_prep.dropna(subset=['Household_Size','Satisfaction_Level','Household_Income'],inplace=True)\n",
    "\n",
    "    ## DATA TYPES ##\n",
    "    df_prep['Household_Income'] = df_prep['Household_Income'].astype('float64')    \n",
    "    df_prep['Household_Size'] = df_prep['Household_Size'].astype('float64')   \n",
    "    df_prep['Satisfaction_Level'] = df_prep['Satisfaction_Level'].astype('float64')    \n",
    "    df_prep['ID_ORIGINAL'] = df_prep['ID_ORIGINAL'].astype('int')  \n",
    "    \n",
    "    ## ENCODING ##\n",
    "    enc_cols = ['Gender', 'Foreign_Citizenship','Frequent_Traveler', 'Cellphone_Usage',\n",
    "                'Occupation', 'Political_Participation','Social_Person', 'Area_Residence', 'Military_Service']\n",
    "    for i in enc_cols:\n",
    "        encode_features(df_prep,i)\n",
    "    \n",
    "    ## FILTER ##\n",
    "    feature_list = ['ID_ORIGINAL', 'Age','Household_Size', 'Satisfaction_Level',\n",
    "       'Household_Income', 'CD_Gender', 'CD_Foreign_Citizenship',\n",
    "       'CD_Frequent_Traveler', 'CD_Cellphone_Usage','CD_Occupation', \n",
    "       'CD_Political_Participation', 'CD_Social_Person','CD_Area_Residence', 'CD_Military_Service']\n",
    "    \n",
    "    X = df_prep[feature_list]\n",
    "    \n",
    "    if 'Spy' in df_prep.columns.tolist():\n",
    "        y = df_prep['Spy']\n",
    "        \n",
    "        # Split train dataset into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "    else:\n",
    "        y = []\n",
    "        X_train = []\n",
    "        X_test = []\n",
    "        y_train = []\n",
    "        y_test = []\n",
    "    \n",
    "\n",
    "    return df_prep, X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e5ac44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep, X, y, X_train, X_test, y_train, y_test = prepare_data(df_train)\n",
    "df_test_prep, X_val, y_, X_train_, X_test_, y_train_, y_test_ = prepare_data(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489cf461",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "51309ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build class to store models and parameters\n",
    "import xgboost as xgb\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "class classification_models:\n",
    "    def __init__(self):\n",
    "        self.baseline = self.baseline()\n",
    "        self.svc = self.svc()\n",
    "        self.naive_bayes = self.naive_bayes()\n",
    "        self.knn = self.knn()\n",
    "        self.logistic_regression = self.logistic_regression()\n",
    "        self.xgboost = self.xgboost()\n",
    "\n",
    "\n",
    "class baseline:\n",
    "    model = DummyClassifier()\n",
    "\n",
    "    parameters = {\n",
    "                   'model__strategy': ['uniform'],\n",
    "                   'model__random_state': [8]\n",
    "                 }\n",
    "\n",
    "    @staticmethod\n",
    "    def best_model(params):\n",
    "        clf = DummyClassifier(**params)\n",
    "        return clf\n",
    "\n",
    "\n",
    "class svc:\n",
    "    model = svm.SVC()\n",
    "\n",
    "    parameters = {'model__C': [0.1, 1, 10, 100],\n",
    "                  'model__gamma': [1, 0.1, 0.01, 0.001],\n",
    "                  'model__kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "    @staticmethod\n",
    "    def best_model(params):\n",
    "        clf = svm.SVC(**params)\n",
    "        return clf\n",
    "\n",
    "\n",
    "class naive_bayes:\n",
    "    model = GaussianNB()\n",
    "\n",
    "    parameters = {\n",
    "                'model__var_smoothing': [1e-2, 1e-4, 1e-6,1e-8,1e-10,1e-12,1e-14,1e-16]\n",
    "                 }\n",
    "\n",
    "    @staticmethod\n",
    "    def best_model(params):\n",
    "        clf = GaussianNB(**params)\n",
    "        return clf\n",
    "\n",
    "class knn:\n",
    "    model = KNeighborsClassifier()\n",
    "\n",
    "    parameters = {'model__n_neighbors': Integer(3, 20),\n",
    "                  'model__weights': Categorical(categories=['uniform', 'distance']),\n",
    "                  'model__algorithm': Categorical(categories=['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "                  'model__leaf_size': Integer(5, 50)\n",
    "                  }\n",
    "\n",
    "    @staticmethod\n",
    "    def best_model(params):\n",
    "        clf = KNeighborsClassifier()\n",
    "        return clf\n",
    "\n",
    "class logistic_regression:\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    parameters = {\n",
    "                   'model__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                   'model__C': [1e-2, 1e-4, 0.01, 0.1,0.3, 0.5,0.8, 1],\n",
    "                   'model__random_state': [8]\n",
    "                 }\n",
    "\n",
    "    @staticmethod\n",
    "    def best_model(params):\n",
    "        clf = LogisticRegression(**params)\n",
    "        return clf\n",
    "\n",
    "class xgboost:\n",
    "    model = xgb.XGBClassifier()\n",
    "\n",
    "    parameters = {\n",
    "                   'model__learning_rate': Real(0.1,1.0,'uniform'),\n",
    "                   'model__max_depth': Integer(2, 100),\n",
    "                   'model__min_samples_leaf': Integer(2, 100),\n",
    "                   'model__min_samples_split': Integer(2, 100),\n",
    "                   'model__subsample': Real(0.1,1.0,'uniform'),\n",
    "                   'model__n_estimators': Integer(10, 100),\n",
    "                   'model__random_state': [16],\n",
    "                 }\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def best_model(params):\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "40bbfae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build models\n",
    "def build_model(X,y,niter,model_list=list):\n",
    "    '''model_list = [baseline, svc, naive_bayes, knn, logistic_regression, xgboost]'''\n",
    "    gsearchs = []\n",
    "    best_models = []\n",
    "    scores = []\n",
    "    best_params = []\n",
    "    cv_results = []\n",
    "    \n",
    "    print('---------------- MODEL TRAINING ----------------')\n",
    "    \n",
    "    for i in model_list:\n",
    "        \n",
    "        string = str(i)\n",
    "        model_name_ = string[string.find('.')+1:]\n",
    "        model_name = model_name_[0:model_name_.find('>')-1].strip()       \n",
    "        print('\\nModel: ', model_name)\n",
    "        \n",
    "        # Get model\n",
    "        model = i.model\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipe = Pipeline([('scaler', MinMaxScaler()),('model',model)])\n",
    "        #pipe = Pipeline([('model',model)])\n",
    "    \n",
    "        # Get hyperparameter grid\n",
    "        param_search = i.parameters\n",
    "        \n",
    "        # Stratified k-fold cross-validation\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        my_cv = [(train,test) for train, test in skf.split(X,y)]\n",
    "        \n",
    "        gsearch = BayesSearchCV(pipe, cv=skf, search_spaces=param_search, n_jobs=10,scoring='f1',\n",
    "                                     verbose=True,refit=True,n_iter=niter)\n",
    "        \n",
    "        \n",
    "        gsearch.fit(X, y)\n",
    "        \n",
    "        '''sorted_idx = gsearch.best_estimator_.named_steps[\"model\"].feature_importances_.argsort()\n",
    "        plt.barh(X.columns[sorted_idx], gsearch.best_estimator_.named_steps[\"model\"].feature_importances_[sorted_idx])\n",
    "        plt.xlabel(\"Xgboost Feature Importance\")'''\n",
    "        \n",
    "        gsearchs.append(gsearch)\n",
    "        best_models.append(gsearch.best_estimator_)\n",
    "        scores.append(gsearch.best_score_)\n",
    "        best_params.append(gsearch.best_params_)\n",
    "        cv_results.append(gsearch.cv_results_)\n",
    "        \n",
    "        print('CV accuracy for model {0}: {1}'.format(model_name,gsearch.best_score_))\n",
    "        \n",
    "    return gsearchs,best_models,scores,best_params,cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d0b779eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- MODEL TRAINING ----------------\n",
      "\n",
      "Model:  svc\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z7/_vrlpskd1ln6jss6825gr50h0000gn/T/ipykernel_71127/1662205590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgsearchs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/z7/_vrlpskd1ln6jss6825gr50h0000gn/T/ipykernel_71127/4096992971.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(X, y, niter, model_list)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mgsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         '''sorted_idx = gsearch.best_estimator_.named_steps[\"model\"].feature_importances_.argsort()\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_kwargs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;31m# BaseSearchCV never ranked train scores,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0mn_points_adjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                 optim_result = self._step(\n\u001b[0m\u001b[1;32m    513\u001b[0m                     \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpoint_asdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mall_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0;31m# Feed the point and objective value back into optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Optimizer minimizes objective, hence provide negative score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gsearchs,best_models,scores,best_params,cv_results = build_model(X_train,y_train,100,model_list=[svc, naive_bayes, knn, xgboost])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297a0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5dfcfb2",
   "metadata": {},
   "source": [
    "## Performance Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(X_test, X_train,y_train, y_test, best_models):\n",
    "    \n",
    "    acc_results = []\n",
    "    f1_results = []\n",
    "    \n",
    "    print('---------------- MODEL EVALUATION ----------------')\n",
    "    \n",
    "    model_counter = 1\n",
    "    for i in best_models:\n",
    "        \n",
    "        string = str(i)\n",
    "        model_name_ = string[string.find(''''model',''')+len(''''model', '''):]\n",
    "        model_name = model_name_[0:model_name_.find('(')].strip() \n",
    "        print('\\nModel #{0}: {1}'.format(model_counter,model_name))\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = i.predict(X_test)        \n",
    "        df_pred = pd.DataFrame(data=y_pred, columns=['Spy'],index=y_test.index)\n",
    "        \n",
    "        # Evaluation metrics\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        f1 = metrics.f1_score(y_test, y_pred, average=None)  \n",
    "        precision = precision_score(y_test, y_pred, average=None)\n",
    "        recall = recall_score(y_test, y_pred, average=None)\n",
    "        \n",
    "        \n",
    "        # Labels to binarize\n",
    "        labels = [0, 1, 2]\n",
    "\n",
    "        # Binarize ytest with shape (n_samples, n_classes)\n",
    "        ytest = label_binarize(y_test, classes=labels)\n",
    "\n",
    "        # Binarize ypreds with shape (n_samples, n_classes)\n",
    "        ypreds = label_binarize(y_pred, classes=labels)\n",
    "        \n",
    "        # Get roc auc result\n",
    "        #roc_auc = roc_auc_score(ytest, ypreds, average=None)\n",
    "        roc_auc = 0\n",
    "        \n",
    "        acc_results.append(accuracy)\n",
    "        f1_results.append(f1)\n",
    "        \n",
    "        print('Accuracy: ',accuracy)\n",
    "        print('Average F1 Score: ',f1.mean())\n",
    "        print('F1 Score by Class: ',f1)\n",
    "        print('Average Precision: ',precision.mean())\n",
    "        print('Precision by Class: ',precision)\n",
    "        print('Average Recall: ',recall)\n",
    "        print('Recall by Class: ',recall.mean())\n",
    "        print('ROC AUC score by Class: ',roc_auc)\n",
    "        #print('Average ROC AUC score: ',roc_auc.mean())\n",
    "        print('\\nConfusion Matrix:\\n',confusion_matrix(y_test, y_pred))\n",
    "        print('\\nClassification Report:\\n',classification_report(y_test, y_pred))\n",
    "        \n",
    "        model_counter+=1\n",
    "    \n",
    "    # Get best model based on accuracy score\n",
    "    maxi_model_nb = acc_results.index(max(acc_results))\n",
    "    \n",
    "    maxi_model = best_models[maxi_model_nb]\n",
    "    string_ = str(maxi_model)\n",
    "    maxi_model_name_ = string_[string_.find(''''model',''')+len(''''model', '''):]\n",
    "    maxi_model_name = maxi_model_name_[0:maxi_model_name_.find('(')].strip() \n",
    "    \n",
    "    \n",
    "    print('\\nBest Model: #{0} {1}'.format(maxi_model_nb+1,maxi_model_name))\n",
    "    \n",
    "    \n",
    "    return acc_results,f1_results, maxi_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76785427",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_results,f1_results,maxi_model = evaluate_model(X_test, X_train, y_train, y_test, best_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6772a2",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab1fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model to disk\n",
    "filename = 'final_model.sav'\n",
    "joblib.dump(maxi_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca99448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = maxi_model.predict(X_val)        \n",
    "df_pred = pd.DataFrame(data=y_pred, columns=['Spy'],index=X_val.index)\n",
    "\n",
    "df_submission = X_val[['ID_ORIGINAL']].merge(df_pred, how='inner', left_index=True, right_index=True, indicator=False)\n",
    "df_submission = df_submission.set_index('ID_ORIGINAL')\n",
    "df_submission.to_csv('submission.csv')\n",
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225536b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score: 0.71162"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
